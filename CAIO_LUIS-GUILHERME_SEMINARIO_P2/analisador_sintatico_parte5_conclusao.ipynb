{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisador Sintático Baseado em Autômatos Finitos - Parte 5: Conclusão\n",
    "\n",
    "Nesta parte final, vamos discutir as conclusões, limitações e possíveis melhorias do analisador sintático baseado em autômatos finitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from syntactic_analyzer import SyntacticAnalyzer\n",
    "from grammar import CATEGORIES, VALID_STRUCTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Resumo do Sistema\n",
    "\n",
    "O analisador sintático baseado em autômatos finitos é uma aplicação prática da teoria dos autômatos na análise de linguagem natural. O sistema implementa um Autômato Finito Determinístico (AFD) para analisar a estrutura sintática de frases em português brasileiro.\n",
    "\n",
    "### 1.1 Componentes Principais\n",
    "\n",
    "O sistema é composto por vários módulos:\n",
    "\n",
    "1. **grammar.py**: Define as categorias gramaticais e estruturas sintáticas válidas\n",
    "2. **automaton.py**: Implementa a estrutura do autômato finito\n",
    "3. **syntactic_analyzer.py**: Implementa o analisador sintático usando o autômato\n",
    "4. **visualize_automaton.py**: Gera visualizações do autômato\n",
    "5. **automaton_gui.py**: Fornece uma interface gráfica para o analisador\n",
    "\n",
    "### 1.2 Fluxo de Processamento\n",
    "\n",
    "O fluxo de processamento do analisador sintático segue estas etapas:\n",
    "\n",
    "1. **Entrada**: Uma frase em português brasileiro\n",
    "2. **Tokenização**: A frase é dividida em tokens (palavras e pontuação)\n",
    "3. **Classificação Gramatical**: Cada token é classificado em uma categoria gramatical (substantivo, verbo, etc.)\n",
    "4. **Mapeamento Sintático**: Cada token recebe uma função sintática (sujeito, verbo, objeto, etc.)\n",
    "5. **Processamento pelo Autômato**: A sequência de funções sintáticas é processada pelo autômato\n",
    "6. **Validação**: O autômato verifica se a sequência forma uma estrutura sintática válida\n",
    "7. **Saída**: O resultado da análise, incluindo as funções sintáticas e a validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limitações do Sistema\n",
    "\n",
    "Embora o analisador sintático seja funcional, ele possui várias limitações que devem ser consideradas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Vocabulário Limitado\n",
    "\n",
    "O sistema utiliza um vocabulário predefinido no módulo `grammar.py`. Palavras que não estão neste vocabulário são classificadas como \"UNKNOWN\" e podem causar erros na análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTIGO: 8 palavras\n",
      "PRONOME: 41 palavras\n",
      "SUBSTANTIVO: 47 palavras\n",
      "VERBO: 122 palavras\n",
      "ADJETIVO: 71 palavras\n",
      "PREPOSICAO: 22 palavras\n",
      "PONTUACAO: 6 palavras\n",
      "CONJUNCAO: 10 palavras\n",
      "ADVERBIO: 25 palavras\n",
      "Total: 352 palavras\n"
     ]
    }
   ],
   "source": [
    "# Verificar o tamanho do vocabulário\n",
    "total_words = 0\n",
    "for category, words in CATEGORIES.items():\n",
    "    print(f\"{category}: {len(words)} palavras\")\n",
    "    total_words += len(words)\n",
    "print(f\"Total: {total_words} palavras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Estruturas Sintáticas Simplificadas\n",
    "\n",
    "O sistema reconhece apenas um conjunto limitado de estruturas sintáticas, definidas no módulo `grammar.py`. Estruturas mais complexas, como orações subordinadas, não são suportadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de estruturas sintáticas válidas: 32\n",
      "\n",
      "Exemplos de estruturas válidas:\n",
      "1. ARTIGO → SUBSTANTIVO → VERBO → ARTIGO → SUBSTANTIVO → PONTUACAO\n",
      "2. SUBSTANTIVO → VERBO → ARTIGO → SUBSTANTIVO → PONTUACAO\n",
      "3. ARTIGO → SUBSTANTIVO → VERBO → SUBSTANTIVO → PONTUACAO\n",
      "4. SUBSTANTIVO → VERBO → SUBSTANTIVO → PONTUACAO\n",
      "5. PRONOME → VERBO → ADJETIVO → PONTUACAO\n"
     ]
    }
   ],
   "source": [
    "# Verificar o número de estruturas sintáticas válidas\n",
    "print(f\"Número de estruturas sintáticas válidas: {len(VALID_STRUCTURES)}\")\n",
    "\n",
    "# Mostrar algumas estruturas como exemplo\n",
    "print(\"\\nExemplos de estruturas válidas:\")\n",
    "for i, structure in enumerate(VALID_STRUCTURES[:5]):\n",
    "    print(f\"{i+1}. {' → '.join(structure)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Não Lida com Ambiguidades\n",
    "\n",
    "O sistema não lida com ambiguidades sintáticas, que são comuns em linguagens naturais. Por exemplo, em \"Ele viu o homem com o telescópio\", não é claro se \"com o telescópio\" se refere a \"viu\" ou a \"homem\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: 'Ele viu o homem com o telescópio.'\n",
      "Estrutura válida: ✗\n",
      "\n",
      "Tokens e funções sintáticas:\n",
      "  - 'ele': PRONOME → SUJEITO\n",
      "  - 'viu': UNKNOWN → DESCONHECIDO\n",
      "  - 'o': ARTIGO → DESCONHECIDO\n",
      "  - 'homem': SUBSTANTIVO → DESCONHECIDO\n",
      "  - 'com': PREPOSICAO → DESCONHECIDO\n",
      "  - 'o': ARTIGO → DESCONHECIDO\n",
      "  - 'telescópio': UNKNOWN → DESCONHECIDO\n",
      "  - '.': PONTUACAO → DESCONHECIDO\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de frase ambígua\n",
    "analyzer = SyntacticAnalyzer()\n",
    "frase_ambigua = \"Ele viu o homem com o telescópio.\"\n",
    "is_valid, syntactic_tokens, _ = analyzer.analyze_sentence(frase_ambigua)\n",
    "\n",
    "print(f\"Frase: '{frase_ambigua}'\")\n",
    "print(f\"Estrutura válida: {'✓' if is_valid else '✗'}\\n\")\n",
    "\n",
    "print(\"Tokens e funções sintáticas:\")\n",
    "for token, category, function in syntactic_tokens:\n",
    "    print(f\"  - '{token}': {category} → {function}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Análise Determinística\n",
    "\n",
    "O sistema usa um Autômato Finito Determinístico (AFD), o que significa que ele segue um único caminho de análise. Isso limita sua capacidade de explorar múltiplas interpretações possíveis de uma frase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Falta de Análise Semântica\n",
    "\n",
    "O sistema realiza apenas análise sintática, não análise semântica. Isso significa que ele pode aceitar frases sintaticamente corretas, mas semanticamente sem sentido, como \"O gato come ideias.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: 'O gato come ideias.'\n",
      "Estrutura válida: ✓\n",
      "\n",
      "Tokens e funções sintáticas:\n",
      "  - 'o': ARTIGO → DET_SUJEITO\n",
      "  - 'gato': SUBSTANTIVO → SUJEITO\n",
      "  - 'come': VERBO → VERBO\n",
      "  - 'ideias': UNKNOWN → DESCONHECIDO\n",
      "  - '.': PONTUACAO → PONTUACAO\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de frase sintaticamente correta, mas semanticamente sem sentido\n",
    "frase_sem_sentido = \"O gato come ideias.\"\n",
    "is_valid, syntactic_tokens, _ = analyzer.analyze_sentence(frase_sem_sentido)\n",
    "\n",
    "print(f\"Frase: '{frase_sem_sentido}'\")\n",
    "print(f\"Estrutura válida: {'✓' if is_valid else '✗'}\\n\")\n",
    "\n",
    "print(\"Tokens e funções sintáticas:\")\n",
    "for token, category, function in syntactic_tokens:\n",
    "    print(f\"  - '{token}': {category} → {function}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Possíveis Melhorias\n",
    "\n",
    "Com base nas limitações identificadas, aqui estão algumas possíveis melhorias para o sistema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Expandir o Vocabulário\n",
    "\n",
    "Uma melhoria óbvia seria expandir o vocabulário para incluir mais palavras em cada categoria gramatical. Isso poderia ser feito manualmente ou usando recursos como dicionários eletrônicos ou corpora linguísticos.\n",
    "\n",
    "Alternativamente, o sistema poderia ser integrado a um analisador morfológico que pudesse classificar palavras desconhecidas com base em sua estrutura (prefixos, sufixos, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Suportar Mais Estruturas Sintáticas\n",
    "\n",
    "O sistema poderia ser estendido para suportar estruturas sintáticas mais complexas, como:\n",
    "\n",
    "- Orações subordinadas\n",
    "- Orações coordenadas\n",
    "- Frases na voz passiva\n",
    "- Frases interrogativas e imperativas\n",
    "- Frases com adjuntos adverbiais em diferentes posições\n",
    "\n",
    "Isso exigiria a expansão do autômato com mais estados e transições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Implementar um Autômato Não-Determinístico\n",
    "\n",
    "Para lidar com ambiguidades sintáticas, o sistema poderia usar um Autômato Finito Não-Determinístico (AFND) em vez de um AFD. Isso permitiria explorar múltiplos caminhos de análise e retornar todas as interpretações possíveis de uma frase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Adicionar Análise Semântica\n",
    "\n",
    "O sistema poderia ser estendido para incluir análise semântica, verificando se as combinações de palavras fazem sentido semanticamente. Isso poderia ser feito usando recursos como WordNet ou modelos de linguagem baseados em aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Integrar com Técnicas de PLN Mais Avançadas\n",
    "\n",
    "O sistema poderia ser integrado com técnicas de Processamento de Linguagem Natural (PLN) mais avançadas, como:\n",
    "\n",
    "- Análise de dependência\n",
    "- Parsing baseado em gramáticas formais (como gramáticas livres de contexto)\n",
    "- Modelos estatísticos ou neurais para análise sintática\n",
    "\n",
    "Isso melhoraria significativamente a precisão e a cobertura do analisador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusão\n",
    "\n",
    "O analisador sintático baseado em autômatos finitos é uma aplicação interessante da teoria dos autômatos na análise de linguagem natural. Embora tenha limitações significativas, ele demonstra como os autômatos podem ser usados para modelar e validar estruturas gramaticais.\n",
    "\n",
    "O sistema atual é uma simplificação da análise sintática real, que é muito mais complexa. No entanto, ele serve como uma base sólida para explorar conceitos de análise sintática e pode ser estendido de várias maneiras para se tornar mais robusto e abrangente.\n",
    "\n",
    "Em resumo, o analisador sintático baseado em autômatos finitos é uma ferramenta educacional valiosa para entender os princípios básicos da análise sintática e da teoria dos autômatos, mesmo que não seja adequado para aplicações práticas de processamento de linguagem natural em escala real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referências\n",
    "\n",
    "- Hopcroft, J. E., Motwani, R., & Ullman, J. D. (2006). Introduction to Automata Theory, Languages, and Computation. Pearson Education.\n",
    "- Jurafsky, D., & Martin, J. H. (2009). Speech and Language Processing. Prentice Hall.\n",
    "- Chomsky, N. (1957). Syntactic Structures. Mouton.\n",
    "- Manning, C. D., & Schütze, H. (1999). Foundations of Statistical Natural Language Processing. MIT Press.\n",
    "- Bird, S., Klein, E., & Loper, E. (2009). Natural Language Processing with Python. O'Reilly Media."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
