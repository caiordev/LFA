{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisador Sintático Baseado em Autômatos Finitos - Parte 4: Implementação\n",
    "\n",
    "Nesta parte, vamos explorar em detalhes a implementação do mapeamento sintático e da interface gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "sys.path.append('.')\n",
    "\n",
    "from syntactic_analyzer import SyntacticAnalyzer\n",
    "from grammar import classify_word, CATEGORIES, is_linking_verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mapeamento Sintático\n",
    "\n",
    "O mapeamento sintático é o processo de atribuir funções sintáticas (sujeito, verbo, objeto, etc.) aos tokens com base em sua posição e categoria gramatical. Este processo é implementado no método `_map_syntactic_functions` da classe `SyntacticAnalyzer`.\n",
    "\n",
    "O método usa uma máquina de estados para acompanhar o contexto sintático durante a análise da frase. Cada estado representa uma posição específica na estrutura da frase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _map_syntactic_functions(self, tokens):\n",
      "        \"\"\"\n",
      "        Mapeia tokens para funções sintáticas com base em sua posição e classe gramatical.\n",
      "        Esta é uma simplificação, pois a análise sintática real é muito mais complexa.\n",
      "        \"\"\"\n",
      "        mapped_tokens = []\n",
      "        state = 0  # Estado atual no processo de mapeamento\n",
      "        \n",
      "        for token, category in tokens:\n",
      "            if state == 0:  # Esperando sujeito ou determinante do sujeito\n",
      "                if category == \"ARTIGO\":\n",
      "                    mapped_tokens.append((token, category, \"DET_SUJEITO\"))\n",
      "                    state = 1\n",
      "                elif category == \"SUBSTANTIVO\":\n",
      "                    mapped_tokens.append((token, category, \"SUJEITO\"))\n",
      "                    state = 2\n",
      "                elif category == \"PRONOME\":\n",
      "                    mapped_tokens.append((token, category, \"SUJEITO\"))\n",
      "                    state = 2\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 1:  # Após determinante do sujeito, esperando sujeito\n",
      "                if category == \"SUBSTANTIVO\":\n",
      "                    mapped_tokens.append((token, category, \"SUJEITO\"))\n",
      "                    state = 2\n",
      "                elif category == \"ADJETIVO\":\n",
      "                    mapped_tokens.append((token, category, \"MODIFICADOR_SUJEITO\"))\n",
      "                    # Continuamos no estado 1, esperando o substantivo\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 2:  # Após sujeito, esperando verbo\n",
      "                if category == \"VERBO\":\n",
      "                    mapped_tokens.append((token, category, \"VERBO\"))\n",
      "                    state = 3\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 3:  # Após reconhecer o verbo, esperando objeto, preposição, advérbio ou pontuação\n",
      "                if category == \"ARTIGO\":\n",
      "                    mapped_tokens.append((token, category, \"DET_OBJETO\"))\n",
      "                    state = 4\n",
      "                elif category == \"SUBSTANTIVO\":\n",
      "                    mapped_tokens.append((token, category, \"OBJETO\"))\n",
      "                    state = 5\n",
      "                elif category == \"ADJETIVO\" and any(t[2] == \"VERBO\" and is_linking_verb(t[0]) for t in mapped_tokens):\n",
      "                    # Se o verbo anterior for de ligação, o adjetivo é predicativo do sujeito\n",
      "                    mapped_tokens.append((token, category, \"PREDICATIVO\"))\n",
      "                    state = 5\n",
      "                elif category == \"VERBO\" and token.endswith('r'):  # Verbo no infinitivo\n",
      "                    mapped_tokens.append((token, category, \"VERBO_INFINITIVO\"))\n",
      "                    state = 5\n",
      "                elif category == \"PREPOSICAO\":\n",
      "                    mapped_tokens.append((token, category, \"PREPOSICAO\"))\n",
      "                    state = 6\n",
      "                elif category == \"ADVERBIO\":\n",
      "                    mapped_tokens.append((token, category, \"ADVERBIO\"))\n",
      "                    state = 5  # Consideramos que após um advérbio podemos ter pontuação\n",
      "                elif category == \"PONTUACAO\":\n",
      "                    mapped_tokens.append((token, category, \"PONTUACAO\"))\n",
      "                    state = 9  # Estado final\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 4:  # Após determinante do objeto, esperando objeto\n",
      "                if category == \"SUBSTANTIVO\":\n",
      "                    mapped_tokens.append((token, category, \"OBJETO\"))\n",
      "                    state = 5\n",
      "                elif category == \"ADJETIVO\":\n",
      "                    mapped_tokens.append((token, category, \"MODIFICADOR_OBJETO\"))\n",
      "                    # Continuamos no estado 4, esperando o substantivo\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 5:  # Após reconhecer o objeto ou advérbio, esperando preposição, advérbio ou pontuação\n",
      "                if category == \"PREPOSICAO\":\n",
      "                    mapped_tokens.append((token, category, \"PREPOSICAO\"))\n",
      "                    state = 6\n",
      "                elif category == \"ADVERBIO\":\n",
      "                    mapped_tokens.append((token, category, \"ADVERBIO\"))\n",
      "                    # Continuamos no estado 5 pois após um advérbio podemos ter pontuação\n",
      "                elif category == \"PONTUACAO\":\n",
      "                    mapped_tokens.append((token, category, \"PONTUACAO\"))\n",
      "                    state = 9  # Estado final\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 6:  # Após reconhecer preposição, esperando determinante ou objeto indireto\n",
      "                if category == \"ARTIGO\":\n",
      "                    mapped_tokens.append((token, category, \"DET_OBJ_IND\"))\n",
      "                    state = 7\n",
      "                elif category == \"SUBSTANTIVO\":\n",
      "                    mapped_tokens.append((token, category, \"OBJ_INDIRETO\"))\n",
      "                    state = 8\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 7:  # Após determinante do objeto indireto, esperando objeto indireto\n",
      "                if category == \"SUBSTANTIVO\":\n",
      "                    mapped_tokens.append((token, category, \"OBJ_INDIRETO\"))\n",
      "                    state = 8\n",
      "                elif category == \"ADJETIVO\":\n",
      "                    mapped_tokens.append((token, category, \"MODIFICADOR_OBJ_IND\"))\n",
      "                    # Continuamos no estado 7, esperando o substantivo\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            elif state == 8:  # Após reconhecer objeto indireto, esperando advérbio ou pontuação\n",
      "                if category == \"PONTUACAO\":\n",
      "                    mapped_tokens.append((token, category, \"PONTUACAO\"))\n",
      "                    state = 9  # Estado final\n",
      "                elif category == \"ADVERBIO\":\n",
      "                    mapped_tokens.append((token, category, \"ADVERBIO\"))\n",
      "                    # Após um advérbio, esperamos pontuação\n",
      "                    state = 8\n",
      "                else:\n",
      "                    mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "            \n",
      "            else:  # Estado desconhecido ou final\n",
      "                mapped_tokens.append((token, category, \"DESCONHECIDO\"))\n",
      "        \n",
      "        return mapped_tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizar o código do método de mapeamento sintático\n",
    "map_syntactic_functions_code = inspect.getsource(SyntacticAnalyzer._map_syntactic_functions)\n",
    "print(map_syntactic_functions_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Estados do Mapeamento Sintático\n",
    "\n",
    "O método `_map_syntactic_functions` usa os seguintes estados:\n",
    "\n",
    "- **Estado 0**: Esperando sujeito ou determinante do sujeito\n",
    "- **Estado 1**: Após reconhecer determinante do sujeito, esperando sujeito\n",
    "- **Estado 2**: Após reconhecer sujeito, esperando verbo\n",
    "- **Estado 3**: Após reconhecer verbo, esperando objeto, advérbio, preposição ou pontuação\n",
    "- **Estado 4**: Após reconhecer determinante do objeto, esperando objeto\n",
    "- **Estado 5**: Após reconhecer objeto ou advérbio, esperando preposição, advérbio ou pontuação\n",
    "- **Estado 6**: Após reconhecer preposição, esperando determinante ou objeto indireto\n",
    "- **Estado 7**: Após reconhecer determinante do objeto indireto, esperando objeto indireto\n",
    "- **Estado 8**: Após reconhecer objeto indireto, esperando advérbio ou pontuação\n",
    "- **Estado 9**: Estado final (após pontuação)\n",
    "\n",
    "Cada estado tem regras específicas para mapear tokens para funções sintáticas e para determinar o próximo estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens classificados:\n",
      "  - 'eu': PRONOME\n",
      "  - 'liguei': VERBO\n",
      "  - 'ao': PREPOSICAO\n",
      "  - 'diretor': SUBSTANTIVO\n",
      "  - 'ontem': ADVERBIO\n",
      "  - '.': PONTUACAO\n",
      "\n",
      "Tokens com funções sintáticas:\n",
      "  - 'eu': PRONOME → SUJEITO\n",
      "  - 'liguei': VERBO → VERBO\n",
      "  - 'ao': PREPOSICAO → PREPOSICAO\n",
      "  - 'diretor': SUBSTANTIVO → OBJ_INDIRETO\n",
      "  - 'ontem': ADVERBIO → ADVERBIO\n",
      "  - '.': PONTUACAO → PONTUACAO\n"
     ]
    }
   ],
   "source": [
    "# Demonstrar o mapeamento sintático com um exemplo\n",
    "analyzer = SyntacticAnalyzer()\n",
    "frase = \"Eu liguei ao diretor ontem.\"\n",
    "\n",
    "# Tokenizar e classificar\n",
    "tokens = analyzer._tokenize_and_classify(frase)\n",
    "print(\"Tokens classificados:\")\n",
    "for token, category in tokens:\n",
    "    print(f\"  - '{token}': {category}\")\n",
    "\n",
    "# Mapear funções sintáticas\n",
    "syntactic_tokens = analyzer._map_syntactic_functions(tokens)\n",
    "print(\"\\nTokens com funções sintáticas:\")\n",
    "for token, category, function in syntactic_tokens:\n",
    "    print(f\"  - '{token}': {category} → {function}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenização e Classificação\n",
    "\n",
    "Antes do mapeamento sintático, a frase precisa ser tokenizada (dividida em palavras) e cada token precisa ser classificado em uma categoria gramatical. Este processo é implementado no método `_tokenize_and_classify` da classe `SyntacticAnalyzer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _tokenize_and_classify(self, sentence):\n",
      "        \"\"\"\n",
      "        Tokeniza e classifica as palavras da frase em categorias gramaticais.\n",
      "        \"\"\"\n",
      "        # Tokenização simples por espaços e remoção de pontuação\n",
      "        tokens = []\n",
      "        current_token = \"\"\n",
      "        \n",
      "        for char in sentence:\n",
      "            if char.isalnum() or char in \"áàâãéèêíìîóòôõúùûçÁÀÂÃÉÈÊÍÌÎÓÒÔÕÚÙÛÇ\":\n",
      "                current_token += char\n",
      "            else:\n",
      "                if current_token:\n",
      "                    tokens.append(current_token.lower())\n",
      "                    current_token = \"\"\n",
      "                if not char.isspace():  # Se não for espaço, é pontuação\n",
      "                    tokens.append(char)\n",
      "        \n",
      "        if current_token:  # Adicionar o último token se existir\n",
      "            tokens.append(current_token.lower())\n",
      "        \n",
      "        # Classificar cada token\n",
      "        classified_tokens = []\n",
      "        i = 0\n",
      "        while i < len(tokens):\n",
      "            token = tokens[i]\n",
      "            # Tratamento especial para contrações como \"ao\" (a + o)\n",
      "            if token == \"ao\" or token == \"aos\":\n",
      "                category = \"PREPOSICAO\"\n",
      "            else:\n",
      "                category = classify_word(token)\n",
      "                if category is None:\n",
      "                    category = \"UNKNOWN\"  # Categoria desconhecida\n",
      "            \n",
      "            classified_tokens.append((token, category))\n",
      "            i += 1\n",
      "        \n",
      "        return classified_tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizar o código do método de tokenização e classificação\n",
    "tokenize_and_classify_code = inspect.getsource(SyntacticAnalyzer._tokenize_and_classify)\n",
    "print(tokenize_and_classify_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Classificação Gramatical\n",
    "\n",
    "A classificação gramatical é realizada pela função `classify_word` no módulo `grammar.py`. Esta função verifica se a palavra está em alguma das categorias gramaticais definidas no dicionário `CATEGORIES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificação gramatical:\n",
      "  - 'o': ARTIGO\n",
      "  - 'gato': SUBSTANTIVO\n",
      "  - 'come': VERBO\n",
      "  - 'peixe': SUBSTANTIVO\n",
      "  - 'rapidamente': ADVERBIO\n",
      "  - 'ao': PREPOSICAO\n",
      "  - 'diretor': SUBSTANTIVO\n",
      "  - 'ontem': ADVERBIO\n",
      "  - 'é': VERBO\n",
      "  - 'bonito': ADJETIVO\n"
     ]
    }
   ],
   "source": [
    "# Demonstrar a classificação gramatical\n",
    "palavras = [\"o\", \"gato\", \"come\", \"peixe\", \"rapidamente\", \"ao\", \"diretor\", \"ontem\", \"é\", \"bonito\"]\n",
    "\n",
    "print(\"Classificação gramatical:\")\n",
    "for palavra in palavras:\n",
    "    categoria = classify_word(palavra)\n",
    "    print(f\"  - '{palavra}': {categoria}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interface Gráfica\n",
    "\n",
    "O sistema inclui uma interface gráfica implementada no módulo `automaton_gui.py`. Esta interface permite ao usuário inserir frases, visualizar a análise sintática e ver o autômato com o caminho percorrido.\n",
    "\n",
    "A interface gráfica é construída usando a biblioteca Tkinter e inclui os seguintes componentes:\n",
    "\n",
    "- Campo de entrada para a frase\n",
    "- Botão para iniciar a análise\n",
    "- Área de texto para mostrar o resultado da análise\n",
    "- Canvas para mostrar a imagem do autômato\n",
    "- Canvas para mostrar a animação do caminho percorrido\n",
    "\n",
    "O método principal que realiza a análise na interface gráfica é `_analyze_sentence` da classe `AutomatonGUI`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Código da Interface Gráfica\n",
    "\n",
    "Aqui está um trecho do código que mostra como a análise sintática é exibida na interface gráfica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def _analyze_sentence(self, event=None):\n",
      "    \"\"Analisa a frase e atualiza a interface.\"\"\n",
      "    sentence = self.sentence_entry.get().strip()\n",
      "\n",
      "    if not sentence:\n",
      "        messagebox.showwarning(\"Aviso\", \"Por favor, digite uma frase para analisar.\")\n",
      "        return\n",
      "\n",
      "    try:\n",
      "        # Analisar a frase e gerar visualizações\n",
      "        image_path, gif_path, is_valid, syntactic_tokens = self.visualizer.visualize_sentence(sentence)\n",
      "\n",
      "        # Atualizar os caminhos das imagens\n",
      "        self.current_image_path = image_path\n",
      "        self.current_gif_path = gif_path\n",
      "\n",
      "        # Atualizar a área de texto com a análise\n",
      "        self.analysis_text.config(state=tk.NORMAL)\n",
      "        self.analysis_text.delete(1.0, tk.END)\n",
      "\n",
      "        self.analysis_text.insert(tk.END, f\"Frase: {sentence}\n",
      "\n",
      "\")\n",
      "        self.analysis_text.insert(tk.END, \"Análise Sintática:\n",
      "\")\n",
      "\n",
      "        for token, category, function in syntactic_tokens:\n",
      "            self.analysis_text.insert(tk.END, f\"  - '{token}': {category} → {function}\n",
      "\")\n",
      "\n",
      "        self.analysis_text.insert(tk.END, f\"\n",
      "Resultado da Análise:\n",
      "\")\n",
      "        if is_valid:\n",
      "            self.analysis_text.insert(tk.END, \"  ✓ Estrutura sintática válida!\n",
      "\")\n",
      "\n",
      "            # Identificar as principais partes da oração\n",
      "            sujeito = [token for token, _, function in syntactic_tokens \n",
      "                      if function in [\"SUJEITO\", \"DET_SUJEITO\", \"MODIFICADOR_SUJEITO\"]]\n",
      "            predicado = [token for token, _, function in syntactic_tokens \n",
      "                        if function not in [\"SUJEITO\", \"DET_SUJEITO\", \"MODIFICADOR_SUJEITO\", \"PONTUACAO\"]]\n",
      "\n",
      "            self.analysis_text.insert(tk.END, \"\n",
      "Partes da Oração:\n",
      "\")\n",
      "            self.analysis_text.insert(tk.END, f\"  - Sujeito: {' '.join(sujeito)}\n",
      "\")\n",
      "            self.analysis_text.insert(tk.END, f\"  - Predicado: {' '.join(predicado)}\n",
      "\")\n",
      "\n",
      "            # Identificar componentes específicos\n",
      "            verbo = [token for token, _, function in syntactic_tokens if function == \"VERBO\"]\n",
      "            objeto_direto = [token for token, _, function in syntactic_tokens \n",
      "                           if function in [\"OBJETO\", \"DET_OBJETO\", \"MODIFICADOR_OBJETO\"]]\n",
      "            objeto_indireto = [token for token, _, function in syntactic_tokens \n",
      "                             if function in [\"OBJ_INDIRETO\", \"DET_OBJ_IND\", \"MODIFICADOR_OBJ_IND\", \"PREPOSICAO\"]]\n",
      "            adverbios = [token for token, _, function in syntactic_tokens if function == \"ADVERBIO\"]\n",
      "\n",
      "            if verbo:\n",
      "                self.analysis_text.insert(tk.END, f\"  - Verbo: {' '.join(verbo)}\n",
      "\")\n",
      "            if objeto_direto:\n",
      "                self.analysis_text.insert(tk.END, f\"  - Objeto Direto: {' '.join(objeto_direto)}\n",
      "\")\n",
      "            if objeto_indireto:\n",
      "                self.analysis_text.insert(tk.END, f\"  - Objeto Indireto: {' '.join(objeto_indireto)}\n",
      "\")\n",
      "            if adverbios:\n",
      "                self.analysis_text.insert(tk.END, f\"  - Advérbio: {' '.join(adverbios)}\n",
      "\")\n",
      "        else:\n",
      "            self.analysis_text.insert(tk.END, \"  ✗ Estrutura sintática inválida!\n",
      "\")\n",
      "            self.analysis_text.insert(tk.END, \"  A frase não segue um padrão sintático reconhecido.\n",
      "\")\n",
      "\n",
      "        self.analysis_text.config(state=tk.DISABLED)\n",
      "\n",
      "        # Atualizar as imagens\n",
      "        self._update_images(image_path, gif_path)\n",
      "\n",
      "    except Exception as e:\n",
      "        messagebox.showerror(\"Erro\", f\"Ocorreu um erro ao analisar a frase: {str(e)}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Código da interface gráfica (não executável no notebook)\n",
    "analyze_sentence_code = \"\"\"\n",
    "def _analyze_sentence(self, event=None):\n",
    "    \"\"Analisa a frase e atualiza a interface.\"\"\n",
    "    sentence = self.sentence_entry.get().strip()\n",
    "    \n",
    "    if not sentence:\n",
    "        messagebox.showwarning(\"Aviso\", \"Por favor, digite uma frase para analisar.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Analisar a frase e gerar visualizações\n",
    "        image_path, gif_path, is_valid, syntactic_tokens = self.visualizer.visualize_sentence(sentence)\n",
    "        \n",
    "        # Atualizar os caminhos das imagens\n",
    "        self.current_image_path = image_path\n",
    "        self.current_gif_path = gif_path\n",
    "        \n",
    "        # Atualizar a área de texto com a análise\n",
    "        self.analysis_text.config(state=tk.NORMAL)\n",
    "        self.analysis_text.delete(1.0, tk.END)\n",
    "        \n",
    "        self.analysis_text.insert(tk.END, f\"Frase: {sentence}\\n\\n\")\n",
    "        self.analysis_text.insert(tk.END, \"Análise Sintática:\\n\")\n",
    "        \n",
    "        for token, category, function in syntactic_tokens:\n",
    "            self.analysis_text.insert(tk.END, f\"  - '{token}': {category} → {function}\\n\")\n",
    "        \n",
    "        self.analysis_text.insert(tk.END, f\"\\nResultado da Análise:\\n\")\n",
    "        if is_valid:\n",
    "            self.analysis_text.insert(tk.END, \"  ✓ Estrutura sintática válida!\\n\")\n",
    "            \n",
    "            # Identificar as principais partes da oração\n",
    "            sujeito = [token for token, _, function in syntactic_tokens \n",
    "                      if function in [\"SUJEITO\", \"DET_SUJEITO\", \"MODIFICADOR_SUJEITO\"]]\n",
    "            predicado = [token for token, _, function in syntactic_tokens \n",
    "                        if function not in [\"SUJEITO\", \"DET_SUJEITO\", \"MODIFICADOR_SUJEITO\", \"PONTUACAO\"]]\n",
    "            \n",
    "            self.analysis_text.insert(tk.END, \"\\nPartes da Oração:\\n\")\n",
    "            self.analysis_text.insert(tk.END, f\"  - Sujeito: {' '.join(sujeito)}\\n\")\n",
    "            self.analysis_text.insert(tk.END, f\"  - Predicado: {' '.join(predicado)}\\n\")\n",
    "            \n",
    "            # Identificar componentes específicos\n",
    "            verbo = [token for token, _, function in syntactic_tokens if function == \"VERBO\"]\n",
    "            objeto_direto = [token for token, _, function in syntactic_tokens \n",
    "                           if function in [\"OBJETO\", \"DET_OBJETO\", \"MODIFICADOR_OBJETO\"]]\n",
    "            objeto_indireto = [token for token, _, function in syntactic_tokens \n",
    "                             if function in [\"OBJ_INDIRETO\", \"DET_OBJ_IND\", \"MODIFICADOR_OBJ_IND\", \"PREPOSICAO\"]]\n",
    "            adverbios = [token for token, _, function in syntactic_tokens if function == \"ADVERBIO\"]\n",
    "            \n",
    "            if verbo:\n",
    "                self.analysis_text.insert(tk.END, f\"  - Verbo: {' '.join(verbo)}\\n\")\n",
    "            if objeto_direto:\n",
    "                self.analysis_text.insert(tk.END, f\"  - Objeto Direto: {' '.join(objeto_direto)}\\n\")\n",
    "            if objeto_indireto:\n",
    "                self.analysis_text.insert(tk.END, f\"  - Objeto Indireto: {' '.join(objeto_indireto)}\\n\")\n",
    "            if adverbios:\n",
    "                self.analysis_text.insert(tk.END, f\"  - Advérbio: {' '.join(adverbios)}\\n\")\n",
    "        else:\n",
    "            self.analysis_text.insert(tk.END, \"  ✗ Estrutura sintática inválida!\\n\")\n",
    "            self.analysis_text.insert(tk.END, \"  A frase não segue um padrão sintático reconhecido.\\n\")\n",
    "        \n",
    "        self.analysis_text.config(state=tk.DISABLED)\n",
    "        \n",
    "        # Atualizar as imagens\n",
    "        self._update_images(image_path, gif_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Erro\", f\"Ocorreu um erro ao analisar a frase: {str(e)}\")\n",
    "\"\"\"\n",
    "\n",
    "print(analyze_sentence_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualização do Autômato\n",
    "\n",
    "A visualização do autômato é implementada no módulo `visualize_automaton.py`. Este módulo usa a biblioteca Graphviz para criar representações gráficas do autômato e do caminho percorrido durante a análise.\n",
    "\n",
    "A visualização inclui:\n",
    "\n",
    "- Uma imagem estática do autômato com o caminho destacado\n",
    "- Uma animação GIF mostrando o processo de análise passo a passo\n",
    "\n",
    "O método principal que cria a visualização é `create_automaton_graph` da classe `AutomatonVisualizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Código da Visualização\n",
    "\n",
    "Aqui está um trecho do código que mostra como o autômato é visualizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código da visualização do autômato (não executável no notebook)\n",
    "create_automaton_graph_code = \"\"\"\n",
    "def create_automaton_graph(self, path=None, highlight_path=True):\n",
    "    \"\"\"\n",
    "    Cria um grafo do autômato usando Graphviz.\n",
    "    \n",
    "    Args:\n",
    "        path: Lista de tuplas (estado, símbolo) representando o caminho percorrido\n",
    "        highlight_path: Se True, destaca o caminho percorrido\n",
    "        \n",
    "    Returns:\n",
    "        Objeto Digraph do Graphviz\n",
    "    \"\"\"\n",
    "    # Criar um novo grafo direcionado\n",
    "    dot = Digraph(comment='Autômato Sintático')\n",
    "    \n",
    "    # Configurar o grafo\n",
    "    dot.attr(rankdir='LR', size='8,5')\n",
    "    dot.attr('node', shape='circle')\n",
    "    \n",
    "    # Definir os estados\n",
    "    states = ['q0', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9']\n",
    "    \n",
    "    # Adicionar estados ao grafo\n",
    "    for state in states:\n",
    "        # Verificar se o estado está no caminho\n",
    "        in_path = False\n",
    "        if path:\n",
    "            for s, _ in path:\n",
    "                if s == state:\n",
    "                    in_path = True\n",
    "                    break\n",
    "        \n",
    "        # Configurar o estilo do estado\n",
    "        if state == 'q9':  # Estado final\n",
    "            if in_path and highlight_path:\n",
    "                dot.node(state, style='filled', color='red', fillcolor='lightpink', shape='doublecircle')\n",
    "            else:\n",
    "                dot.node(state, shape='doublecircle')\n",
    "        else:  # Estados não-finais\n",
    "            if in_path and highlight_path:\n",
    "                dot.node(state, style='filled', color='red', fillcolor='lightpink')\n",
    "            else:\n",
    "                dot.node(state)\n",
    "    \n",
    "    # Definir as transições\n",
    "    transitions = [\n",
    "        ('q0', 'q1', 'DET_SUJEITO'),\n",
    "        ('q0', 'q2', 'SUJEITO'),\n",
    "        ('q1', 'q2', 'SUJEITO'),\n",
    "        ('q2', 'q3', 'VERBO'),\n",
    "        ('q3', 'q4', 'DET_OBJETO'),\n",
    "        ('q3', 'q5', 'OBJETO'),\n",
    "        ('q3', 'q5', 'PREDICATIVO'),\n",
    "        ('q3', 'q5', 'VERBO_INFINITIVO'),\n",
    "        ('q3', 'q5', 'ADVERBIO'),\n",
    "        ('q3', 'q6', 'PREPOSICAO'),\n",
    "        ('q3', 'q9', 'PONTUACAO'),\n",
    "        ('q4', 'q5', 'OBJETO'),\n",
    "        ('q5', 'q6', 'PREPOSICAO'),\n",
    "        ('q5', 'q5', 'ADVERBIO'),\n",
    "        ('q5', 'q9', 'PONTUACAO'),\n",
    "        ('q6', 'q7', 'DET_OBJ_IND'),\n",
    "        ('q6', 'q8', 'OBJ_INDIRETO'),\n",
    "        ('q7', 'q8', 'OBJ_INDIRETO'),\n",
    "        ('q8', 'q8', 'ADVERBIO'),\n",
    "        ('q8', 'q9', 'PONTUACAO')\n",
    "    ]\n",
    "    \n",
    "    # Adicionar transições ao grafo\n",
    "    for src, dst, label in transitions:\n",
    "        # Verificar se a transição está no caminho\n",
    "        in_path = False\n",
    "        if path:\n",
    "            for i in range(1, len(path)):\n",
    "                prev_state, symbol = path[i-1][0], path[i][1]\n",
    "                curr_state = path[i][0]\n",
    "                if prev_state == src and curr_state == dst and symbol == label:\n",
    "                    in_path = True\n",
    "                    break\n",
    "        \n",
    "        # Configurar o estilo da transição\n",
    "        if in_path and highlight_path:\n",
    "            dot.edge(src, dst, label=label, color='red', penwidth='2.0')\n",
    "        else:\n",
    "            dot.edge(src, dst, label=label)\n",
    "    \n",
    "    return dot\n",
    "\"\"\"\n",
    "\n",
    "print(create_automaton_graph_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Executando a Interface Gráfica\n",
    "\n",
    "Para executar a interface gráfica, você pode usar o seguinte comando no terminal:\n",
    "\n",
    "```bash\n",
    "python automaton_gui.py\n",
    "```\n",
    "\n",
    "Isso abrirá uma janela com a interface gráfica, onde você pode inserir frases para análise e ver o resultado, incluindo a visualização do autômato."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
